{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AdamW, BertTokenizer, BertModel\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "from tqdm.notebook import tqdm\n",
    "from kobert_tokenizer import KoBERTTokenizer\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##GPU 사용 시\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, tokenizer, dataloader, device):\n",
    "    \"\"\"\n",
    "    Evaluate the model using Precision, Recall, and F1-Score.\n",
    "\n",
    "    Args:\n",
    "        model: Trained PyTorch model.\n",
    "        tokenizer: Tokenizer for preprocessing.\n",
    "        dataloader: DataLoader for evaluation data.\n",
    "        device: Device to run the model (GPU or CPU).\n",
    "\n",
    "    Returns:\n",
    "        None. Prints evaluation metrics.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            # Assuming batch[3] contains labels\n",
    "            texts, labels = batch[0], batch[3]\n",
    "\n",
    "            # Ensure texts is a List[str]\n",
    "            if isinstance(texts, torch.Tensor):\n",
    "                texts = [str(t) for t in texts]\n",
    "\n",
    "            # Tokenize input text\n",
    "            inputs = tokenizer(\n",
    "                texts,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "                max_length=128\n",
    "            )\n",
    "\n",
    "            # Move inputs and labels to the specified device\n",
    "            inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Get predictions\n",
    "            outputs = model(**inputs)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            # Collect true and predicted labels\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            pred_labels.extend(preds.cpu().numpy())\n",
    "\n",
    "        # Convert multi-dimensional true_labels to single dimension if needed\n",
    "        if len(true_labels) > 0 and isinstance(true_labels[0], (list, np.ndarray)):\n",
    "            true_labels = [label.argmax() for label in true_labels]\n",
    "\n",
    "    # Debugging outputs\n",
    "    print(f\"True Labels (example): {true_labels[:10]}\")\n",
    "    print(f\"Predicted Labels (example): {pred_labels[:10]}\")\n",
    "    print(f\"Unique classes in true_labels: {set(true_labels)}\")\n",
    "    print(f\"Unique classes in pred_labels: {set(pred_labels)}\")\n",
    "\n",
    "    unique_classes = set(true_labels + pred_labels)\n",
    "\n",
    "    if len(unique_classes) == 1:\n",
    "        print(f\"Warning: Only one class ({list(unique_classes)[0]}) detected.\")\n",
    "        print(\"Cannot generate complete classification report.\")\n",
    "    else:\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(true_labels, pred_labels, target_names=['ham', 'spam'], labels=[0, 1]))\n",
    "        print(f\"Precision: {precision_score(true_labels, pred_labels, average='binary'):.4f}\")\n",
    "        print(f\"Recall: {recall_score(true_labels, pred_labels, average='binary'):.4f}\")\n",
    "        print(f\"F1-Score: {f1_score(true_labels, pred_labels, average='binary'):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 로드\n",
    "train_df = pd.read_csv('/home/maroco/dataset/model/train_set.csv')\n",
    "test_df = pd.read_csv('/home/maroco/dataset/model/test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블 변환 (예: 'spam' → 1, 'ham' → 0)\n",
    "label_map = {'spam': 1, 'ham': 0}\n",
    "train_df['label'] = train_df['label'].map(label_map)\n",
    "test_df['label'] = test_df['label'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 정의\n",
    "class KoBERTDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Tokenization\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_len\n",
    "        )\n",
    "\n",
    "        input_ids = inputs['input_ids'].squeeze(0)\n",
    "        attention_mask = inputs['attention_mask'].squeeze(0)\n",
    "        token_type_ids = inputs['token_type_ids'].squeeze(0)\n",
    "\n",
    "        return input_ids, attention_mask, token_type_ids, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert  # Pre-trained BERT 모델\n",
    "        # 개선된 분류층 추가\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(bert.config.hidden_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 2)  # 이진 분류를 위해 클래스 수는 2\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        # BERT 모델의 출력을 받아 분류층으로 전달\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        pooled_output = outputs[1]  # [CLS] 토큰의 임베딩\n",
    "        return self.classifier(pooled_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "max_len = 128\n",
    "batch_size = 64\n",
    "learning_rate = 5e-5\n",
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'KoBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"monologg/kobert\")\n",
    "bert_model = BertModel.from_pretrained(\"monologg/kobert\")\n",
    "model = BERTClassifier(bert_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and DataLoader\n",
    "train_texts = train_df['text'].tolist()  # 텍스트 열에서 리스트로 변환\n",
    "train_labels = train_df['label'].tolist()  # 레이블 열에서 리스트로 변환\n",
    "\n",
    "test_texts = test_df['text'].tolist()\n",
    "test_labels = test_df['label'].tolist()\n",
    "\n",
    "# 레이블 인코딩 ('ham'과 'spam'을 각각 0과 1로 변환)\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(train_labels)  # 'ham' -> 0, 'spam' -> 1\n",
    "\n",
    "# Dataset 생성\n",
    "train_dataset = KoBERTDataset(\n",
    "    texts=train_texts,\n",
    "    labels=train_labels,\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    ")\n",
    "\n",
    "test_dataset = KoBERTDataset(\n",
    "    texts=test_texts,\n",
    "    labels=test_labels,\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    ")\n",
    "\n",
    "# DataLoader 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수 및 옵티마이저 설정 (클래스 가중치 포함)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=[0, 1], y=y_train)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maroco/anaconda3/envs/kobert_env/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# # Optimizer and Scheduler\n",
    "# optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "# scheduler = get_cosine_schedule_with_warmup(\n",
    "#     optimizer,\n",
    "#     num_warmup_steps=len(train_loader) * 2,\n",
    "#     num_training_steps=len(train_loader) * num_epochs\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "# loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy calculation\n",
    "def calc_accuracy(preds, labels):\n",
    "    _, pred_classes = preds.max(dim=1)\n",
    "    return (pred_classes == labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d54ee50e124e90994e9b702ebe9445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7414 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 0.0881 | Train Accuracy: 0.9615\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f9bfecdfc664ce3985a3f7a16e1cfac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Val Loss: 0.0543 | Val Accuracy: 0.9746\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026e41f17d2749e68d1c438e8093a31e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7414 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 0.1291 | Train Accuracy: 0.9439\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7264e29373b64706956c54ad24bc80d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Val Loss: 1.0464 | Val Accuracy: 0.2019\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6005650ac29f44a6ac9c911f4804a5cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7414 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 0.1790 | Train Accuracy: 0.9209\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0deef04e49d247f4bde3ead1228915ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Val Loss: 1.3240 | Val Accuracy: 0.2019\n"
     ]
    }
   ],
   "source": [
    "# Training and Validation loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_acc, total_loss = 0, 0\n",
    "\n",
    "    # Training phase\n",
    "    for input_ids, attention_mask, token_type_ids, labels in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        token_type_ids = token_type_ids.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_acc += calc_accuracy(outputs, labels)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {total_loss / len(train_loader):.4f} | Train Accuracy: {total_acc / len(train_dataset):.4f}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask, token_type_ids, labels in tqdm(test_loader):\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            token_type_ids = token_type_ids.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_acc += calc_accuracy(outputs, labels)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Val Loss: {total_loss / len(test_loader):.4f} | Val Accuracy: {total_acc / len(test_dataset):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치만 저장\n",
    "torch.save(model.state_dict(), \"/home/maroco/dataset/model/sentiment_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch type: <class 'list'>\n",
      "Batch content: [tensor([[   2,    0,    0,  ...,    1,    1,    1],\n",
      "        [   2,    0,    0,  ...,    1,    1,    1],\n",
      "        [   2,    0,    0,  ...,    1,    1,    1],\n",
      "        ...,\n",
      "        [   2,    0,    0,  ...,    1,    1,    1],\n",
      "        [   2,    0, 5782,  ...,    1,    1,    1],\n",
      "        [   2,    0,    0,  ...,  365,  365,    3]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1])]\n"
     ]
    }
   ],
   "source": [
    "for batch in test_loader:\n",
    "    print(f\"Batch type: {type(batch)}\")\n",
    "    print(f\"Batch content: {batch}\")\n",
    "    break  # 한 배치만 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in test dataset: {0, 1}\n"
     ]
    }
   ],
   "source": [
    "all_labels = []\n",
    "for batch in test_loader:\n",
    "    labels = batch[3]  # 네 번째 텐서에서 레이블 추출\n",
    "    all_labels.extend(labels.numpy())\n",
    "\n",
    "print(f\"Unique labels in test dataset: {set(all_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Labels (example): [0, 1, 1, 1, 1, 1, 0, 1, 0, 1]\n",
      "Predicted Labels (example): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Unique classes in true_labels: {0, 1}\n",
      "Unique classes in pred_labels: {0}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.20      1.00      0.34     23943\n",
      "        spam       0.00      0.00      0.00     94671\n",
      "\n",
      "    accuracy                           0.20    118614\n",
      "   macro avg       0.10      0.50      0.17    118614\n",
      "weighted avg       0.04      0.20      0.07    118614\n",
      "\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maroco/anaconda3/envs/kobert_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/maroco/anaconda3/envs/kobert_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/maroco/anaconda3/envs/kobert_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/maroco/anaconda3/envs/kobert_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "evaluate_model(model, tokenizer, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 사용 중지 함수\n",
    "def cleanup_gpu():\n",
    "    \"\"\"\n",
    "    Releases GPU memory and clears PyTorch GPU cache.\n",
    "    \"\"\"\n",
    "    # Synchronize to ensure all GPU operations are complete\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()  # Waits for all kernels to finish\n",
    "        torch.cuda.empty_cache()  # Releases all unused cached memory\n",
    "        print(\"GPU memory has been released.\")\n",
    "    else:\n",
    "        print(\"No GPU detected. No action taken.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory has been released.\n"
     ]
    }
   ],
   "source": [
    "cleanup_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kobert_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
