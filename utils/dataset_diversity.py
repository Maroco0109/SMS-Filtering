import pandas as pd
import numpy as np
from collections import Counter
from sklearn.feature_extraction.text import CountVectorizer

def evaluate_diversity(csv_path, text_col='proc_text', label_col='label'):
    df = pd.read_csv(csv_path)
    total_samples = len(df)
    spam_count = (df[label_col] == 0).sum()
    ham_count = (df[label_col] == 1).sum()

    # ë¬¸ì¥ ê¸¸ì´
    df['len'] = df[text_col].apply(lambda x: len(str(x).split()))
    avg_len = df['len'].mean()
    spam_len = df[df[label_col] == 0]['len'].mean()
    ham_len = df[df[label_col] == 1]['len'].mean()

    # Vocabulary Size
    all_tokens = ' '.join(df[text_col].astype(str)).split()
    vocab_size = len(set(all_tokens))

    # n-gram ì¤‘ë³µë„ (bi-gram)
    vectorizer = CountVectorizer(ngram_range=(2, 2))
    ngram_counts = vectorizer.fit_transform(df[text_col].astype(str))
    total_ngrams = ngram_counts.sum()
    unique_ngrams = len(vectorizer.vocabulary_)
    ngram_dup_ratio = 1 - (unique_ngrams / total_ngrams)

    print(f"\nğŸ“„ Dataset Overview")
    print(f"- ì´ ìƒ˜í”Œ ìˆ˜: {total_samples}")
    print(f"- ìŠ¤íŒ¸ ìƒ˜í”Œ ìˆ˜: {spam_count}")
    print(f"- í–„ ìƒ˜í”Œ ìˆ˜: {ham_count}")

    print(f"\nğŸ“Š ë‹¤ì–‘ì„± ì§€í‘œ")
    print(f"- ì „ì²´ ê³ ìœ  ë‹¨ì–´ ìˆ˜: {vocab_size}")
    print(f"- í‰ê·  ë¬¸ì¥ ê¸¸ì´: {avg_len:.2f} í† í°")
    print(f"- ìŠ¤íŒ¸ í‰ê·  ê¸¸ì´: {spam_len:.2f}, í–„ í‰ê·  ê¸¸ì´: {ham_len:.2f}")
    print(f"- 2-gram ì¤‘ë³µë„: {ngram_dup_ratio*100:.2f}%")

if __name__ == '__main__':
    csv_path = '/home/maroco/SMS-Filtering/data/proc_data.csv'  # ë˜ëŠ” train/valid csv
    evaluate_diversity(csv_path)
