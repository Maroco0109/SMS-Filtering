# Spam SMS Filtering with Natural language models

1. About Project

- NLPëª¨ë¸ë“¤ì„ í™œìš©í•˜ì—¬ ìŠ¤íŒ¸ ë©”ì„¸ì§€ë¥¼ í•„í„°ë§í•˜ëŠ” ëª¨ë¸ êµ¬í˜„
  - ìŠ¤íŒ¸ ë©”ì„¸ì§€ì— í•´ë‹¹í•˜ëŠ” ì¹´í…Œê³ ë¦¬ë¥¼ ì„¤ì •í•˜ì—¬ KoBERT ëª¨ë¸ì„ í†µí•´ í•´ë‹¹ SMSê°€ ìŠ¤íŒ¸ ì¹´í…Œê³ ë¦¬ì— í¬í•¨ë˜ëŠ”ì§€ íŒŒì•…í•˜ì—¬ í•„í„°ë§
  - ì—¬ëŸ¬ í•œêµ­ì–´ ì²˜ë¦¬ pre-trained ëª¨ë¸ ì‚¬ìš© ë° ì„±ëŠ¥ ë¹„êµ ë¶„ì„(https://github.com/monologg)
  - KoBERT
  - KoELECTRA
  - KoRoberta
  - KoBigBird
- Sentiment Predict Example
  - ![Sentiment Predict Example](https://github.com/user-attachments/assets/094c3de1-eddc-4d16-b66e-29129824343b)

2. Project Setup

- Model Development Environmnet
  - Anaconda3 in Windows 11
    - GPU setup for deep learning(RTX 3060 12gb)
      - CUDA
      - CuDNN
  - Python
    - Pytorch
- Project architecture
  - ![SMS Filtering](https://github.com/user-attachments/assets/511bd687-edcf-4e68-bd1f-88dc86e59242)

## ğŸ“‚ Directory Structure

```bash
Spam SMS Filtering/
â”œâ”€â”€ data/ # ì›ë³¸ ë° ì „ì²˜ë¦¬ ë°ì´í„° ì €ì¥
â”‚ â”œâ”€â”€ raw/ # ì›ë³¸ ë°ì´í„°
â”‚ â””â”€â”€ preprocessed/ # ì „ì²˜ë¦¬ëœ ë°ì´í„°
â”œâ”€â”€ preprocess/
â”‚ â”œâ”€â”€ build_dataset.py
â”‚ â”œâ”€â”€ merge_sms_datasets.py
â”‚ â”œâ”€â”€ preprocess.py
â”‚ â”œâ”€â”€ process_test.py
â”‚ â””â”€â”€ util.py
â”œâ”€â”€ templates/
â”‚ â”œâ”€â”€ index.html  # demo.py web page
â”œâ”€â”€ utils/
â”‚ â”œâ”€â”€ __init__.py
â”‚ â”œâ”€â”€ convert_to_onnx.py   # pt to onnx
â”‚ â”œâ”€â”€ data_util.py   # ë°ì´í„° í† í°í™”
â”‚ â”œâ”€â”€ dataset_diversity.py # dataset ë¶„í¬ í™•ì¸
â”‚ â”œâ”€â”€ demo_console.py   # user inputì„ consoleì—ì„œ ë°›ëŠ” demo
â”‚ â”œâ”€â”€ demo.py  # user inputì„ webì—ì„œ ë°›ëŠ” demo
â”‚ â”œâ”€â”€ export_model.py   # ckpt to pt
â”‚ â”œâ”€â”€ logger.py   # Log íŒŒì¼ ìƒì„±
â”‚ â”œâ”€â”€ model_util.py  # í•œêµ­ì–´ LLM
â”‚ â””â”€â”€ predict_text.py   # ê°ì„± ë¶„ì„
â”œâ”€â”€ main.py # ë©”ì¸
â”œâ”€â”€ plm.py  # ëª¨ë¸ í˜¸ì¶œ ë° í›ˆë ¨
â”œâ”€â”€ dataloader.py # ë°ì´í„°ë¡œë”
â”œâ”€â”€ eval.py # ëª¨ë¸ í‰ê°€
â”œâ”€â”€ requirements.txt # í•„ìš”í•œ Python íŒ¨í‚¤ì§€ ë¦¬ìŠ¤íŠ¸
â”œâ”€â”€ main.py # ì „ì²´ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹¤í–‰í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ README.md # í”„ë¡œì íŠ¸ ì„¤ëª…
```

## ğŸ“‹ Description

ì´ í”„ë¡œì íŠ¸ëŠ” **í•œêµ­ì–´ ì²˜ë¦¬ LLM**ì„ í™œìš©í•˜ì—¬ ìŠ¤íŒ¸ ë©”ì‹œì§€ì™€ ì •ìƒ ë©”ì‹œì§€ë¥¼ ë¶„ë¥˜í•˜ëŠ” ëª¨ë¸ì„ êµ¬ì¶•í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. ë°ì´í„° ì „ì²˜ë¦¬, í•™ìŠµ, í‰ê°€ ê³¼ì •ì„ í†µí•´ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì„±í•˜ë©°, ê°ê°ì˜ ê³¼ì •ì€ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“ˆë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

---

## ğŸš€ How to Run

1. **í™˜ê²½ ì„¤ì •**:

```bash
pip install -r requirements.txt
```

2. ë°ì´í„° ì „ì²˜ë¦¬:

```bash
python utils/data_preprocessing.py
```

### without testcase

```bash
python build_dataset.py --split --data_dir ../data --save_dir ../result
```

### with testcase

```bash
python build_dataset.py --split --use_test --data_dir ../data --save_dir ../result
```

3. ëª¨ë¸ í•™ìŠµ:

### Arguments

- model_type: bert, electra, roberta, bigbird
- model_name: bert+revised, electra+revised, roberta+revised, bigbird+revised
- max_len: í•™ìŠµì— ì‚¬ìš©í•  ë¬¸ì¥ ê¸¸ì´(64, 128, 256, ...)
- gpuid: 0(default), 1(if using 2nd gpu)
- use_custom_classifier: custom classifierë¥¼ ì‚¬ìš©í•  ë•Œ(default: pure LLM)
- use_focal_loss: focal lossë¥¼ ì‚¬ìš©í•  ë•Œ(default: cross entrophy)
- threshold 0.xx: threshold ì¡°ì • ì‹œ(default: 0.5)

```bash
python main.py --train --data_dir result \
--model_type {model} \
--model_name {model+revised} \
--max_len {hprams} \
--gpuid 0 \
--use_custom_classifier \
--use_focal_loss \
--threshold {0.xx}
```

4. í…ŒìŠ¤íŠ¸:

### Arguments

- model_pt: í•™ìŠµ ì™„ë£Œëœ ckpt íŒŒì¼ ê²½ë¡œ

#### pred\_{model}+revised.csv ìƒì„±

```bash
python main.py --pred --data_dir result \
--model_type {model} \
--model_name {model+revised} \
--model_pt {model.ckpt directory} \
--max_len {hparams.yaml ì°¸ì¡°} \
--gpuid 0 \
--use_custom_classifier \
--use_focal_loss \
--threshold=0.6
```

#### ckpt test with user inputs

```bash
python utils/predict_text.py \
--model_type {model} \
--model_pt {model.ckpt directory} \
--gpuid 0
```

### pred\_{model}+revised.csv ë°ì´í„° ë¶„í¬ ì¶œë ¥

```bash
python utils/test_case.py \
--model_type {model}
```

5. ëª¨ë¸ ì¶”ì¶œ

### ckpt to pt

```bash
python utils/export_model.py \
--model_type {model} \
--model_pt {.ckpt file directory} \
--max_len {hparams.yaml ì°¸ì¡°} \
--output_dir {.pt file directory} \
--hparams_path {hparams.yaml directory}
```

### pt to onnx

```bash
python utils/convert_to_onnx.py \
--model_type {model}
```

## Version Issues

### Pytorch 2.7.0, Cuda 12.7

- Pytorch 2.7.0, transformers 4.46.3 ì—ì„œ ì—°ì‚°ì ë¬¸ì œ ë°œìƒ
  - Scaled dot product attention

### í•´ê²° ë°©ë²•

- Pytorch = 2.3.1, transformers = 4.26.1, cuda = 11.8

```bash
pip install torch==2.3.1+cu118 torchvision==0.16.1+cu118 torchaudio==2.3.1 --index-url https://download.pytorch.org/whl/cu118
```

```bash
pip install transformers==4.26.1

```

- ê¸°íƒ€ íŒ¨í‚¤ì§€

```bash
pip install pytorch-lightning==2.0.9 torchmetrics==0.11.4
```
